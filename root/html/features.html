<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Expression Recognition - Home</title>
    <link rel="stylesheet" href="/root/styles/features.css">
</head>
<body>
    <!-- Navigation Bar -->
    <header class="header">
        <div class="container">
            <nav class="navbar">
                <div class="logo">
                    <h1>FaceRec</h1>
                </div>
                <ul class="nav-links">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="features.html">Features</a></li>
                    <li><a href="practice.html">Practice</a></li>
                    <li><a href="resume.html">Resume Builder</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </nav>
        </div>
    </header>


    <!-- Main Content Section -->
    <section class="main-content">
        <div class="container">
            <div class="content-grid">
                    <div class="feature-item">
                        <h3>Real-Time Emotion Detection</h3>
                        Real-time emotion detection enhances your web app by analyzing facial expressions to understand user emotions during the interview.</p>
                        Here’s a concise breakdown:</p>
                        Facial Recognition: The app uses the camera to capture the user’s face, detecting facial landmarks through computer vision libraries like OpenCV.
                        Emotion Classification: Pre-trained machine learning models, such as convolutional neural networks (CNNs), classify emotions based on facial features, identifying expressions like happiness or sadness.
                        Real-Time Processing: The app continuously analyzes video frames, providing instant feedback on emotional changes using technologies like TensorFlow.js.
                        Data Visualization: Real-time emotional data is visually represented through graphs, helping both candidates and interviewers understand emotional dynamics.
                        Benefits: This feature offers insights into candidate confidence and engagement, leading to more informed hiring decisions while promoting fairness in evaluations.
                    </div>
                    <div class="feature-item">
                        <h3>Eye Contact Monitoring</h3>
                        <p>Track eye movements to measure how much attention a candidate is giving to the interviewer.</p>
                        <p>
                            Eye Contact Monitoring Overview
                            Eye contact monitoring is an innovative feature that enhances user interactions by tracking gaze patterns during interviews. Here’s a concise breakdown:
                            
                            Gaze Detection: The app uses the webcam to analyze eye movements, identifying where the user is looking. It employs computer vision techniques, such as eye-tracking algorithms, to ensure accuracy.
                            Attention Measurement: By determining the frequency and duration of eye contact with the interviewer, the system assesses engagement levels. This analysis can indicate a candidate's confidence and interest in the conversation.
                            Real-Time Feedback: The monitoring happens live, allowing immediate feedback to both candidates and interviewers. If gaze patterns suggest disengagement, the app can prompt the candidate to refocus their attention.
                            Data Visualization: Insights are displayed through charts and graphs, showcasing eye contact patterns over time, which can help interviewers gauge overall attentiveness.
                            Benefits: This feature supports more informed hiring decisions by providing objective metrics on candidate engagement and interaction quality. It promotes a more interactive and dynamic interview environment.</p>
                    </div>
                    <div class="feature-item">
                        <h3>Graphical Data Reports</h3>
                        <p>Graphical data reports provide an efficient way to visualize emotional engagement metrics during interviews. By collecting and processing data on emotional indicators such as confidence and attention levels, the web app generates intuitive visualizations like line graphs and bar charts. These graphics allow users to easily interpret patterns and trends, helping interviewers understand candidate dynamics better. With a user-friendly interface, the reports enable quick assessments and informed decision-making based on the data collected. Additionally, they adhere to ethical considerations regarding data privacy and transparency, ensuring users feel secure about how their information is handled.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>
</body>
</html>
